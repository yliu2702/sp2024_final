# -*- coding: utf-8 -*-
"""BERT_LIAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10K_m3VRYZtRSy2sp7U4RaGzTWXI18Ndj

#### Fine-tuned BERTï¼š[link text](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#11-using-colab-gpu-for-training)
"""
# !pip install transformers
# !pip install tqdm
from base.helper import *
from base.constant import *
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset, Subset
import sys
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from tqdm import tqdm
from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification

# print("DEMO_SAVE_PATH: ", DEMO_SAVE_PATH)
# print("DATA_BASE_DIR: ", DATA_BASE_DIR) 
# exit()


## TODO: adjust hyperparameters
MAX_LEN = 256
TRAIN_BATCH_SIZE =4
VALID_BATCH_SIZE = 1
EPOCHS = 15
LEARNING_RATE = 1e-5
optim = "AdamW"
weight_decay = 2*1e-3

## TODO: change save path (not data path)
DEMO_SAVE_PATH_1 = DEMO_SAVE_PATH + f"/subset/{TRAIN_BATCH_SIZE}_{optim}_{LEARNING_RATE}_{weight_decay}"

CACHE_DIR = os.environ.get("TRANSFORMERS_CACHE")
create_directory(DEMO_SAVE_PATH_1)

logger = Logger(f"{DEMO_SAVE_PATH_1}/logs.log")

tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-cased")

train_df = pd.read_csv(DATA_BASE_DIR + "/model/train.csv")
val_df = pd.read_csv(DATA_BASE_DIR + "/model/val.csv")

train_data = CustomDataset(train_df, tokenizer, MAX_LEN)
val_data = CustomDataset(val_df, tokenizer, MAX_LEN)

train_data =  Subset(train_data, range(100))
val_dataset = Subset(val_data, range(10))

# train_data =  Subset(train_data, range(len(train_data)))
# val_dataset = Subset(val_data, range(len(val_data)))

train_data_loader = torch.utils.data.DataLoader(
    train_data,
    shuffle = True,
    batch_size = TRAIN_BATCH_SIZE,
    num_workers = 0 # num_workers = 0, means use all the gpu available
)
val_data_loader = torch.utils.data.DataLoader(
    val_data,
    shuffle = True,
    batch_size = VALID_BATCH_SIZE,
    num_workers = 0
)

"""### Model"""
## TODO: choose a pretrained model
model = AutoModelForSequenceClassification.from_pretrained("google-bert/bert-base-cased", num_labels=6, cache_dir=CACHE_DIR)
## TODO: choose an optimizer 
optimizer = torch.optim.AdamW(params = model.parameters(), lr=LEARNING_RATE, weight_decay=weight_decay)

print("There are ",torch.cuda.device_count(), "GPUs available to use")
if torch.cuda.device_count() > 1:
    model = torch.nn.DataParallel(model)

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)


# from transformers import get_linear_schedule_with_warmup

"""#### Training
- Unpack our data inputs and labels
- Load data onto the GPU for acceleration
- Clear out the gradients calculated in the previous pass.
  - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.
- Forward pass (feed input data through the network)
- Backward pass (backpropagation)
- Tell the network to update parameters with optimizer.step()
- Track variables for monitoring progress
"""

def train(train_loader, model, optimizer, device, progress_bar):
    num_steps = 0
    train_loss = 0
    train_acc = 0
    model.train()
    for index, batch in progress_bar:
        # unpack inputs and labels
        input_ids = batch['input_ids'].to(device, dtype = torch.long)
        attention_mask = batch['attention_mask'].to(device, dtype = torch.long)
        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)
        targets = batch['target'].to(device, dtype = torch.long)   # torch.long store index/label; float store weights/bias
        outputs = model(input_ids, attention_mask, token_type_ids)
        # print(outputs)
        # Clear the gradients, because gradients are accumulated, and you would like to avoid mixing
        optimizer.zero_grad()
        # Forward Pass
        loss = loss_fn(outputs.logits, targets)
        if torch.cuda.device_count() > 1:
          loss = loss.mean()
        # optimizer.zero_grad()
        # Backward Pass
        loss.backward()
        # Clip the norm of the gradients to 1.0, prevent exploding gradients
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        # update the model parameters
        optimizer.step()

        # metric
        train_loss += loss.item()
        outputs_numpy = outputs.logits.detach().cpu().numpy()
        label_numpy = targets.to('cpu').numpy()
        train_acc += flat_acc(outputs_numpy, label_numpy)
         # Update progress bar with loss info
        progress_bar.set_postfix({"loss": loss.item()})
        # if num_steps % 100 ==0 and num_steps>0:
        #     print(f"loss at step: {num_steps}: {train_loss/(train_loader.batch_size * num_steps)}")
        #     print(f"acc at step: {num_steps}: {train_acc/(num_steps)}")

        num_steps += index

    avg_train_loss = train_loss / len(train_loader)
    avg_train_acc = train_acc / len(train_loader)
    return avg_train_loss, avg_train_acc

# evaluate the model every n iteration
def evaluate(logger,epoch,val_loader, model):
    num_steps = 0
    val_loss = 0
    val_acc = 0
    model.eval()
    for index, batch in enumerate(val_loader):
        input_ids = batch['input_ids'].to(device, dtype = torch.long)
        attention_mask = batch['attention_mask'].to(device, dtype = torch.long)
        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)
        targets = batch['target'].to(device, dtype = torch.long)   # torch.long store index/label; float store weights/bias

        # in validation, we don't need to update parameters, we just validate the performance under new dataset
        with torch.no_grad():
            outputs = model(input_ids, attention_mask, token_type_ids)
            loss = loss_fn(outputs.logits, targets)
        val_loss += loss.item()
        outputs_numpy = outputs.logits.detach().cpu().numpy()
        label_numpy = targets.to('cpu').numpy()
        val_acc += flat_acc(outputs_numpy, label_numpy)

        # if num_steps % 3 ==0 and num_steps>0:
        #     print(f"loss at step: {num_steps}: {val_loss/(val_loader.batch_size * num_steps)}")
        #     print(f"acc at step: {num_steps}: {val_acc/(num_steps)}")
        num_steps += index
    avg_val_loss = val_loss / len(val_loader)
    avg_val_acc = val_acc / len(val_loader)
    return avg_val_loss, avg_val_acc


ckp_path = f"{DEMO_SAVE_PATH_1}/checkpointing/checkpoint/current_checkpoint.pt"
best_model_path = f"{DEMO_SAVE_PATH_1}/checkpointing/best_model/best_model.pt"

# def train_model(n_epochs, train_loader, val_loader, model, optimizer, device, checkpoint_path, best_model_path):
train_loss, train_acc = [], []
val_loss, val_acc = [], []
best_acc = 0
valid_loss_min = np.Inf

for e in range(1, EPOCHS+1):
    progress_bar = tqdm(enumerate(train_data_loader), total = len(train_data_loader), desc="Training")
    avg_train_loss, avg_train_acc = train(train_data_loader, model, optimizer, device, progress_bar)
    logger.info(f"Training Loss at epoch {e}: {avg_train_loss}")
    if e % 1 == 0: 
        avg_val_loss, avg_val_acc = evaluate(logger, e, val_data_loader, model)
        logger.info(f"Validation Score at epoch {e}: {avg_val_acc}")
        if avg_val_acc > best_acc:
            best_acc = avg_val_acc
            model.save_pretrained(f"{DEMO_SAVE_PATH_1}/best_model")
            logger.info(f"New best accuracy: {best_acc}. Best model saved at epoch {e}")
        
        checkpoint = {
            'epoch': e,
            'valid_loss_min': avg_val_loss,   # loss in validation can be a good indicator
            'state_dict': model.state_dict(),
            'optimizer': optimizer.state_dict(),
        }
        save_ckp(checkpoint, False, ckp_path, best_model_path)








